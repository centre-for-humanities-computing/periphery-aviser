{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96139480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/ucloud/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/ucloud/.local/lib/python3.12/site-packages (2.2.5)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.1.6)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ucloud/.local/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ucloud/.local/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ucloud/.local/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ucloud/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ucloud/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ucloud/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ucloud/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ucloud/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "Installing collected packages: xxhash, tqdm, threadpoolctl, scipy, regex, pyarrow, propcache, pillow, multidict, kiwisolver, joblib, fsspec, frozenlist, fonttools, filelock, dill, cycler, contourpy, aiohappyeyeballs, yarl, scikit-learn, nltk, multiprocess, matplotlib, huggingface-hub, aiosignal, seaborn, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 contourpy-1.3.2 cycler-0.12.1 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 fonttools-4.57.0 frozenlist-1.6.0 fsspec-2024.12.0 huggingface-hub-0.30.2 joblib-1.4.2 kiwisolver-1.4.8 matplotlib-3.10.1 multidict-6.4.3 multiprocess-0.70.16 nltk-3.9.1 pillow-11.2.1 propcache-0.3.1 pyarrow-19.0.1 regex-2024.11.6 scikit-learn-1.6.1 scipy-1.15.2 seaborn-0.13.2 threadpoolctl-3.6.0 tqdm-4.67.1 xxhash-3.5.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn nltk tqdm datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5514fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41630158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac116fa1",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ecc9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91497d4de2404af7ba9ac0f2f2169c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2add839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce08b249aa4449ca302a423f941485e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554cf55fce704a61baae68f1d35d7353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/16 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9155230e5a84eec88025e1d37e190da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00016.parquet:   0%|          | 0.00/379M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940724aa268640e29456bcd2a6f9714d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00016.parquet:   0%|          | 0.00/379M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b565494642e43f185bbb285b23b1039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00016.parquet:   0%|          | 0.00/385M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132f8a73136c4b548dc658233ec268e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00016.parquet:   0%|          | 0.00/400M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aed871622d4b57be6ceee4e1116455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00016.parquet:   0%|          | 0.00/403M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6ff059dac0483e90289c62299e323e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00016.parquet:   0%|          | 0.00/396M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81000d876547476cb17fd5a838517cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00016.parquet:   0%|          | 0.00/407M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b897502d775247328c1f0ca08a968608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00016.parquet:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72599173401d40e4878869f7b4cf0c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00016.parquet:   0%|          | 0.00/398M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cded3cf5f64d0982b6bc7c4a3aea44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00016.parquet:   0%|          | 0.00/388M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1065f611b094525a3f0e078acbd1994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00016.parquet:   0%|          | 0.00/380M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf2684be3b34bb8ba0b481c77718c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00016.parquet:   0%|          | 0.00/387M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a4ad39f00b4567aa329cab1d9c5763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00016.parquet:   0%|          | 0.00/395M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64366d1ced7e40639d7e0917552ed6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00016.parquet:   0%|          | 0.00/389M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d559b4b07524c0ab20d7a5cae1a5d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00016.parquet:   0%|          | 0.00/387M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4de470ea0ad48a8a6513f06a92e7628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00016.parquet:   0%|          | 0.00/395M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394e9cfec1a940e08e2d34e30f5e01d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/866977 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(866977, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"chcaa/periphery-aviser-e5\", split='train')\n",
    "\n",
    "df = dataset.to_pandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9428ad",
   "metadata": {},
   "source": [
    "### Load annotated books subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3768208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>book_announce</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264863</th>\n",
       "      <td>ode_023787</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151177</th>\n",
       "      <td>aal_066100</td>\n",
       "      <td>n</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379019</th>\n",
       "      <td>ode_138229</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483748</th>\n",
       "      <td>thi_040569</td>\n",
       "      <td>n</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369240</th>\n",
       "      <td>ode_128401</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id book_announce comment\n",
       "264863  ode_023787             y     NaN\n",
       "151177  aal_066100             n   mixed\n",
       "379019  ode_138229             n     NaN\n",
       "483748  thi_040569             n   mixed\n",
       "369240  ode_128401             n     NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_gold = pd.read_csv('../../newspaper_temp_files/annotated_books_gold.csv', index_col=0)\n",
    "book_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f17c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(book_gold, on='article_id', how='left')\n",
    "df['book_announce'] = df['book_announce'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a6a3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_announce\n",
       "n             546\n",
       "unknown    866177\n",
       "y             254\n",
       "Name: book_announce, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('book_announce')['book_announce'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9771978",
   "metadata": {},
   "source": [
    "### Classifier with unlabeled announcements and book announcements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample of unlabeled announcements\n",
    "unlabeled_df = df[(df['book_announce'] == 'unknown') & (df['clean_category'] == 'Bekjendtgjørelser')]\n",
    "random_sample_unlabeled = unlabeled_df.sample(n=230, random_state=42)\n",
    "\n",
    "# Create sample of labeled book announcements\n",
    "random_sample_books = df[df['book_announce'] == 'y'].sample(n=230, random_state=42)\n",
    "\n",
    "merged_sample = pd.concat([random_sample_unlabeled, random_sample_books])\n",
    "merged_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ffcf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classifier on embeddings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     unknown       0.98      0.93      0.96        69\n",
      "           y       0.93      0.99      0.96        69\n",
      "\n",
      "    accuracy                           0.96       138\n",
      "   macro avg       0.96      0.96      0.96       138\n",
      "weighted avg       0.96      0.96      0.96       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the balanced data into train and test sets with stratification\n",
    "train_df, test_df = train_test_split(\n",
    "    merged_sample, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=merged_sample['book_announce']\n",
    ")\n",
    "\n",
    "# Prepare training and test features/labels\n",
    "X_train = np.vstack(train_df['embedding'].values)\n",
    "y_train = train_df['book_announce'].values\n",
    "\n",
    "X_test = np.vstack(test_df['embedding'].values)\n",
    "y_test = test_df['book_announce'].values\n",
    "\n",
    "# Instantiate the Logistic Regression classifier\n",
    "clf_embs = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "\n",
    "# Train the classifier on the labeled training data\n",
    "print(f'Train classifier on embeddings')\n",
    "clf_embs.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "predictions = clf_embs.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc4c21",
   "metadata": {},
   "source": [
    "### Classifier with non-book announcements and book announcements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c013b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1352/922224328.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df_books.groupby('book_announce', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Define the number of samples per class (adjust based on dataset size)\n",
    "n_samples_per_class = 254  # Change as needed\n",
    "\n",
    "df_books = df[df['book_announce'] != 'unknown']\n",
    "\n",
    "# Create a balanced dataset by sampling an equal number of instances per class\n",
    "df_balanced = df_books.groupby('book_announce', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), n_samples_per_class), random_state=42)\n",
    ")\n",
    "\n",
    "# Split the balanced data into train and test sets with stratification\n",
    "train_df, test_df = train_test_split(\n",
    "    df_balanced, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=df_balanced['book_announce']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3733854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classifier on embeddings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.85      0.87      0.86        77\n",
      "           y       0.86      0.84      0.85        76\n",
      "\n",
      "    accuracy                           0.86       153\n",
      "   macro avg       0.86      0.86      0.86       153\n",
      "weighted avg       0.86      0.86      0.86       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare training and test features/labels\n",
    "X_train = np.vstack(train_df['embedding'].values)\n",
    "y_train = train_df['book_announce'].values\n",
    "\n",
    "X_test = np.vstack(test_df['embedding'].values)\n",
    "y_test = test_df['book_announce'].values\n",
    "\n",
    "# Instantiate the Logistic Regression classifier\n",
    "clf_embs = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "\n",
    "# Train the classifier on the labeled training data\n",
    "print(f'Train classifier on embeddings')\n",
    "clf_embs.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "predictions = clf_embs.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa48dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classifier on TF-IDF features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.89      0.81      0.84        77\n",
      "           y       0.82      0.89      0.86        76\n",
      "\n",
      "    accuracy                           0.85       153\n",
      "   macro avg       0.85      0.85      0.85       153\n",
      "weighted avg       0.85      0.85      0.85       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit on training data and transform both train and test sets\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Prepare labels\n",
    "y_train = train_df['book_announce'].values\n",
    "y_test = test_df['book_announce'].values\n",
    "\n",
    "# Instantiate the Logistic Regression classifier\n",
    "clf_tfidf = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "\n",
    "# Train the classifier on the TF-IDF features\n",
    "print(f'Train classifier on TF-IDF features')\n",
    "clf_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "predictions = clf_tfidf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bf4f6",
   "metadata": {},
   "source": [
    "### Label unlabeled articles as book announcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655c108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336210, 15)\n",
      "(182237, 15)\n"
     ]
    }
   ],
   "source": [
    "# Only get the announcements that have not been categorized as book anouncement yet\n",
    "pred_df = df[(df['book_announce'] == 'unknown') & (df['clean_category'] == 'Bekjendtgjørelser')]\n",
    "print(pred_df.shape)\n",
    "\n",
    "# Identify the top 188 most frequent 'text' values (appearing 5 times or more)\n",
    "top_188_texts = pred_df.groupby('text')['text'].count().sort_values(ascending=False).head(188).index\n",
    "\n",
    "# Remove rows in 'pred_df' where the 'text' is in the top 188 texts\n",
    "pred_df = pred_df[~pred_df['text'].isin(top_188_texts)]\n",
    "\n",
    "# Remove lottery results\n",
    "pred_df = pred_df[~pred_df['text'].str.contains(r'Ved Tallotteriets \\S+ Trækning i', regex=True)]\n",
    "\n",
    "# Remove very long and short articles\n",
    "pred_df = pred_df[(pred_df['characters'] >= 70) & (pred_df['characters'] <= 500)]\n",
    "print(pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f9e4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_embs = np.vstack(pred_df['embedding'].values)\n",
    "\n",
    "pred_df['predicted_book_announce'] = clf_embs.predict(X_test_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de769e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_book_announce\n",
       "n    167891\n",
       "y     14346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['predicted_book_announce'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d4be23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_announce\n",
       "unknown    866177\n",
       "n             546\n",
       "y             254\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['book_announce'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6ffcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14600, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_announces = pd.concat([pred_df[pred_df['predicted_book_announce'] == 'y'], df[df['book_announce'] == 'y']])\n",
    "book_announces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46a30fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_announces.to_csv('../data/book_announces_250422.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb819e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
