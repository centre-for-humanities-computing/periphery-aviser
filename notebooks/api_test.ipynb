{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f648763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.82.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ucloud/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ucloud/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ucloud/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ucloud/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading openai-1.82.1-py3-none-any.whl (720 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.5/720.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-inspection, tqdm, threadpoolctl, rapidfuzz, pydantic-core, numpy, joblib, jiter, annotated-types, scipy, pydantic, pandas, scikit-learn, openai\n",
      "Successfully installed annotated-types-0.7.0 jiter-0.10.0 joblib-1.5.1 numpy-2.2.6 openai-1.82.1 pandas-2.2.3 pydantic-2.11.5 pydantic-core-2.33.2 pytz-2025.2 rapidfuzz-3.13.0 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0 tqdm-4.67.1 typing-inspection-0.4.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas tqdm rapidfuzz scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6389b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from rapidfuzz import fuzz, process\n",
    "import time\n",
    "from openai import RateLimitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c604eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for API keys and models\n",
    "llm_config = {\n",
    "    \"openai\": {\n",
    "        \"api_key\": \"MASKED\",  # Replace with your actual API key\n",
    "        \"models\": {\n",
    "            \"default\": \"gpt-4o-mini\",\n",
    "            \"advanced\": \"gpt-4\",\n",
    "            \"economy\": \"gpt-4o-mini\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize clients with API keys from config\n",
    "# Choose which provider(s) you want to use and comment out the others if you don't have all API keys\n",
    "openai_client = OpenAI(api_key=llm_config[\"openai\"][\"api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648339f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document(document_text):\n",
    "    \"\"\"\n",
    "    Analyze a Danish 19th-century newspaper announcement and extract book titles and authors.\n",
    "\n",
    "    Args:\n",
    "        document_text (str): The text of the document to analyze.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame or str: DataFrame with extracted entities or 'NO BOOKS'.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "    \"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\\n\\n\"\n",
    "    \"original_title: <title in Danish>\\n\"\n",
    "    \"translated_title: <title in English>\\n\"\n",
    "    \"author: <author name>\\n\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an author’s name.\\n\"\n",
    "    \"2. If the announcement mentions multiple book titles, extract each one separately. Ensure each title is uniquely identified.\\n\"\n",
    "    \"3. If the author is missing or unclear, use 'NO_AUTHOR'. Verify the context to ensure the correct identification of authors.\\n\"\n",
    "    \"4. Translate the original Danish title into English yourself for the 'translated_title'. Ensure the translation preserves the meaning and context of the original title.\\n\"\n",
    "    \"5. Pay special attention to context - announcements may contain other text (e.g., product listings, theater plays, chapter titles) that should not be considered book titles. Identify keywords that separate book titles from other content.\\n\"\n",
    "    \"6. If no book titles are present, return exactly one row with:\\n\"\n",
    "    \"   original_title: NO_BOOK\\n\"\n",
    "    \"   translated_title: NO_BOOK\\n\"\n",
    "    \"   author: NO_BOOK\\n\\n\"\n",
    "    \"Examples with books:\\n\"\n",
    "    \"Example1: 'Baggesens allerældste Poesier'.\\n\"\n",
    "    \"→ original_title: allerældste Poesier; translated_title: Oldest Poems; author: Baggesen\\n\"\n",
    "    \"Example2: 'Kateketisk Magasin af J. C. Wegener, Forstander for det Kongelige Skolelærer-Seminarium paa Joenstrup.'\\n\"\n",
    "    \"→ original_title: Kateketisk Magasin; translated_title: Catechetical Magazine; author: J.C. Wegener\\n\"\n",
    "    \"Example3: 'Ceres. Et periodisk Skrivt for dannede Læsere. Udgiver af F. M. Lange. Femte Hefte. Det indeholder: Juliette, eller det hemmelige Ægteskab, af Frederik Kind. - Jagtgildet, af Washington Irving. Subskription modtages hos Vogelius, Boghandler og Bogbinder.'\\n\"\n",
    "    \"→ original_title: Juliette, eller det hemmelige Ægteskab; translated_title: Juliette, or The Secret Marriage; author: Frederik Kind\\n\"\n",
    "    \"→ original_title: Jagtgildet; translated_title: The Hunting Feast; author: Washington Irving\\n\\n\"\n",
    "    \"Examples without books:\\n\"\n",
    "    \"Example1: 'J. Et Parti gode hjemmegjorte Bolster og Dynevaar er i Dag arriveret og sælges billigst muligt af M. N. Samson.'\\n\"\n",
    "    \"→ original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example2: 'C. Andersen. Første Afdeling: 'Spanierne i Odense, Vaudeville i 1 Act. Anden Afdeling: 'Fem og tyve Aar derefter i Helsingøer, Vaudeville i 1 Act. Billetter a 2 Mk. 8 s., (Børn det Halve) erholdes i mit Logie hos Hr. Kobbersmed Schmidt. Hvo som tager 6 Billetter erholder disse for 2 A. Werligh. Rbd.' This is a theater announcement.\\n\"\n",
    "    \"→ original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example3: 'Første Binds andet Hefte, indeholdende følgende Katekisationer: 1 Den ægtekristelige Menneskekjærlighed bør være ufortrøden, virksom, uegennyttig og viis 2 Om de Glæder, den sande Menneskekjærlighed skjænker os 5 Om Guds Almagt; 4 Om Guds Alvidenhed; 5 OmGuds Viisdom; 6 Til Lærebogens 6 Kap. 1. 2. 5, 7 Religion er Menneskets vigtigste Anliggende.' These are chapter titles.\\n\"\n",
    "    \"→ original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Use these guidelines and examples to enhance extraction accuracy and maintain the required output format.\\n\"\n",
    ")\n",
    "\n",
    "    try:\n",
    "        model = llm_config[\"openai\"][\"models\"][\"default\"]\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": document_text}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=800\n",
    "        )\n",
    "\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        if result_text.upper() == \"NO BOOKS\":\n",
    "            return \"NO BOOKS\"\n",
    "\n",
    "        # Extract structured results\n",
    "        pattern = re.compile(\n",
    "            r\"original_title:\\s*(.*?)\\ntranslated_title:\\s*(.*?)\\nauthor:\\s*(.*?)(?:\\n|$)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        entries = [\n",
    "            {\n",
    "                \"original_title\": match.group(1).strip(),\n",
    "                \"translated_title\": match.group(2).strip(),\n",
    "                \"author\": match.group(3).strip()\n",
    "            }\n",
    "            for match in pattern.finditer(result_text)\n",
    "        ]\n",
    "\n",
    "        return pd.DataFrame(entries)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing document with OpenAI: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd85656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI BOOK TITLE EXTRACTION:\n",
      "                                   original_title  \\\n",
      "0                 Niels Klims underjordiske Reise   \n",
      "1  Opfordring til Lollands og Falsters Jndbyggere   \n",
      "2                                         NO_BOOK   \n",
      "\n",
      "                                   translated_title          author  \n",
      "0                  Niels Klim's Underground Journey      L. Holberg  \n",
      "1  Appeal to the Inhabitants of Lolland and Falster  K. H. Seidelin  \n",
      "2                                           NO_BOOK         NO_BOOK  \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage in a notebook\n",
    "sample_document = \"\"\"\n",
    "Paa Addresse-Contoiret i Mariboe er pr. Commission til Salg et nitid Exemplar af Pragt-Udgaven af Niels Klims underjordiske Reise ved L. Holberg. Oversat efter den lanske Original af Jens Baggesen Kbh. 1789, m. sine Kobb. Prisen er 4 Rd. D. C. Hr. Lientenant K. H. Seidelins Opfordring til Lollands og Falsters Jndbyggere, at tilberede raae Salpeter, med Prosessor Maschmanns Underretning om Salpeters Tilvirkning, kan paa Addresse-Contoiret. i Mariboe bekommes gratis.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"OPENAI BOOK TITLE EXTRACTION:\")\n",
    "openai_summary = analyze_document(sample_document)\n",
    "print(openai_summary)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf2a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "      <th>n_chunks_orig</th>\n",
       "      <th>clean_category</th>\n",
       "      <th>nøgle</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>article_length</th>\n",
       "      <th>characters</th>\n",
       "      <th>embedding_shape</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>label_type</th>\n",
       "      <th>book_announce</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_book_announce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lol_000038</td>\n",
       "      <td>1809-03-07</td>\n",
       "      <td>[ 0.03518467  0.00932873 -0.0178937  ... -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-03-07_52</td>\n",
       "      <td>Paa Addresse-Contoiret i Mariboe bekommes følg...</td>\n",
       "      <td>Bekiendtgiørelser</td>\n",
       "      <td>76</td>\n",
       "      <td>475</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>lol_000109</td>\n",
       "      <td>1809-03-17</td>\n",
       "      <td>[ 0.02211799  0.00355701 -0.02588731 ... -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-03-17_174</td>\n",
       "      <td>Maskeradeballet i Dannemark 1808. Et Syn af N....</td>\n",
       "      <td>Bekiendtgiørelser</td>\n",
       "      <td>84</td>\n",
       "      <td>495</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>lol_000189</td>\n",
       "      <td>1809-03-28</td>\n",
       "      <td>[ 0.04022709  0.02202421 -0.01741452 ... -0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-03-28_306</td>\n",
       "      <td>Maskeradeballet i Dannemark 1808. Et Syn af N....</td>\n",
       "      <td>Bekiendtgiørelser</td>\n",
       "      <td>29</td>\n",
       "      <td>148</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>lol_000330</td>\n",
       "      <td>1809-04-18</td>\n",
       "      <td>[ 0.02150071  0.00016588 -0.00461735 ... -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-04-18_554</td>\n",
       "      <td>Alle Slags Bogbinder-Arbeide, saavel nyt, som ...</td>\n",
       "      <td>Bekiendtgiørelser</td>\n",
       "      <td>50</td>\n",
       "      <td>341</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>lol_000476</td>\n",
       "      <td>1809-05-09</td>\n",
       "      <td>[ 0.0191186   0.00117065 -0.01776858 ... -0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-05-09_826</td>\n",
       "      <td>Paa Addresse-Contoiret i Mariboe er pr. Commis...</td>\n",
       "      <td>Bekiendtgiørelser</td>\n",
       "      <td>70</td>\n",
       "      <td>469</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id        date  \\\n",
       "37   lol_000038  1809-03-07   \n",
       "108  lol_000109  1809-03-17   \n",
       "188  lol_000189  1809-03-28   \n",
       "328  lol_000330  1809-04-18   \n",
       "470  lol_000476  1809-05-09   \n",
       "\n",
       "                                             embedding  n_chunks_orig  \\\n",
       "37   [ 0.03518467  0.00932873 -0.0178937  ... -0.02...              1   \n",
       "108  [ 0.02211799  0.00355701 -0.02588731 ... -0.00...              1   \n",
       "188  [ 0.04022709  0.02202421 -0.01741452 ... -0.01...              1   \n",
       "328  [ 0.02150071  0.00016588 -0.00461735 ... -0.02...              1   \n",
       "470  [ 0.0191186   0.00117065 -0.01776858 ... -0.03...              1   \n",
       "\n",
       "        clean_category           nøgle  \\\n",
       "37   Bekjendtgjørelser   1809-03-07_52   \n",
       "108  Bekjendtgjørelser  1809-03-17_174   \n",
       "188  Bekjendtgjørelser  1809-03-28_306   \n",
       "328  Bekjendtgjørelser  1809-04-18_554   \n",
       "470  Bekjendtgjørelser  1809-05-09_826   \n",
       "\n",
       "                                                  text           category  \\\n",
       "37   Paa Addresse-Contoiret i Mariboe bekommes følg...  Bekiendtgiørelser   \n",
       "108  Maskeradeballet i Dannemark 1808. Et Syn af N....  Bekiendtgiørelser   \n",
       "188  Maskeradeballet i Dannemark 1808. Et Syn af N....  Bekiendtgiørelser   \n",
       "328  Alle Slags Bogbinder-Arbeide, saavel nyt, som ...  Bekiendtgiørelser   \n",
       "470  Paa Addresse-Contoiret i Mariboe er pr. Commis...  Bekiendtgiørelser   \n",
       "\n",
       "     article_length  characters embedding_shape newspaper label_type  \\\n",
       "37               76         475          [1024]       lol       gold   \n",
       "108              84         495          [1024]       lol       gold   \n",
       "188              29         148          [1024]       lol       gold   \n",
       "328              50         341          [1024]       lol       gold   \n",
       "470              70         469          [1024]       lol       gold   \n",
       "\n",
       "    book_announce comment predicted_book_announce  \n",
       "37        unknown     NaN                       y  \n",
       "108       unknown     NaN                       y  \n",
       "188       unknown     NaN                       y  \n",
       "328       unknown     NaN                       y  \n",
       "470       unknown     NaN                       y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load book announcements\n",
    "book_announces = pd.read_csv('../data/book_announces_250503.csv', index_col=0)\n",
    "book_announces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c9b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample with the gold standard articles\n",
    "\n",
    "gold_df = pd.read_csv(\"../../newspaper_temp_files/training_testing_titles.csv\", index_col=0)\n",
    "\n",
    "random_sample = book_announces[book_announces['article_id'].isin(gold_df['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb3b0dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "      <th>n_chunks_orig</th>\n",
       "      <th>clean_category</th>\n",
       "      <th>nøgle</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>article_length</th>\n",
       "      <th>characters</th>\n",
       "      <th>embedding_shape</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>label_type</th>\n",
       "      <th>book_announce</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_book_announce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>lol_001393</td>\n",
       "      <td>1809-09-29</td>\n",
       "      <td>[ 0.05600849  0.01557517 -0.02665625 ... -0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-09-29_2574</td>\n",
       "      <td>Løier Et Brev paa Vers til Joh. Nordahl Bruun,...</td>\n",
       "      <td>Bekiendtgiørelser</td>\n",
       "      <td>33</td>\n",
       "      <td>185</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>lol_001834</td>\n",
       "      <td>1809-12-12</td>\n",
       "      <td>[ 0.01884314  0.02579251  0.0012215  ... -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1809-12-12_3367</td>\n",
       "      <td>Bekjendtgjørelser. Jndbydelse. Da udenlandske ...</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>45</td>\n",
       "      <td>296</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>lol_001987</td>\n",
       "      <td>1810-01-09</td>\n",
       "      <td>[ 0.03172351  0.02591745 -0.00467053 ... -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1810-01-09_3675</td>\n",
       "      <td>Bekjendtgjørelser. Gudstjenesten begynder 2den...</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>30</td>\n",
       "      <td>196</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>lol_002560</td>\n",
       "      <td>1810-03-22</td>\n",
       "      <td>[-0.00690638  0.02288655 -0.03385538 ...  0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1810-03-22_4723</td>\n",
       "      <td>Disse sande skjulte Menneskevenner takkes paa ...</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>lol_003135</td>\n",
       "      <td>1810-06-05</td>\n",
       "      <td>[ 0.03199682  0.00117054 -0.01987574 ... -0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>1810-06-05_5778</td>\n",
       "      <td>Tanker i Anledning af Skrivelsen fra Falster, ...</td>\n",
       "      <td>Bekjendtgjørelser</td>\n",
       "      <td>22</td>\n",
       "      <td>130</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id        date  \\\n",
       "1382  lol_001393  1809-09-29   \n",
       "1822  lol_001834  1809-12-12   \n",
       "1975  lol_001987  1810-01-09   \n",
       "2547  lol_002560  1810-03-22   \n",
       "3121  lol_003135  1810-06-05   \n",
       "\n",
       "                                              embedding  n_chunks_orig  \\\n",
       "1382  [ 0.05600849  0.01557517 -0.02665625 ... -0.03...              1   \n",
       "1822  [ 0.01884314  0.02579251  0.0012215  ... -0.02...              1   \n",
       "1975  [ 0.03172351  0.02591745 -0.00467053 ... -0.00...              1   \n",
       "2547  [-0.00690638  0.02288655 -0.03385538 ...  0.00...              1   \n",
       "3121  [ 0.03199682  0.00117054 -0.01987574 ... -0.01...              1   \n",
       "\n",
       "         clean_category            nøgle  \\\n",
       "1382  Bekjendtgjørelser  1809-09-29_2574   \n",
       "1822  Bekjendtgjørelser  1809-12-12_3367   \n",
       "1975  Bekjendtgjørelser  1810-01-09_3675   \n",
       "2547  Bekjendtgjørelser  1810-03-22_4723   \n",
       "3121  Bekjendtgjørelser  1810-06-05_5778   \n",
       "\n",
       "                                                   text           category  \\\n",
       "1382  Løier Et Brev paa Vers til Joh. Nordahl Bruun,...  Bekiendtgiørelser   \n",
       "1822  Bekjendtgjørelser. Jndbydelse. Da udenlandske ...  Bekjendtgjørelser   \n",
       "1975  Bekjendtgjørelser. Gudstjenesten begynder 2den...  Bekjendtgjørelser   \n",
       "2547  Disse sande skjulte Menneskevenner takkes paa ...  Bekjendtgjørelser   \n",
       "3121  Tanker i Anledning af Skrivelsen fra Falster, ...  Bekjendtgjørelser   \n",
       "\n",
       "      article_length  characters embedding_shape newspaper label_type  \\\n",
       "1382              33         185          [1024]       lol       gold   \n",
       "1822              45         296          [1024]       lol       gold   \n",
       "1975              30         196          [1024]       lol       gold   \n",
       "2547              12          79          [1024]       lol       gold   \n",
       "3121              22         130          [1024]       lol       gold   \n",
       "\n",
       "     book_announce comment predicted_book_announce  \n",
       "1382       unknown     NaN                       y  \n",
       "1822       unknown     NaN                       y  \n",
       "1975       unknown     NaN                       y  \n",
       "2547       unknown     NaN                       y  \n",
       "3121       unknown     NaN                       y  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3db49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random sample\n",
    "\n",
    "#random_sample = book_announces.sample(n=300, random_state=42)\n",
    "\n",
    "#random_sample = book_announces.groupby('newspaper').sample(n=50, random_state=42)\n",
    "#random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a143a0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 293/293 [05:34<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# This will hold individual mini-DataFrames returned by analyze_document\n",
    "books_dfs = []\n",
    "\n",
    "for idx, row in tqdm(random_sample.iterrows(), total=len(random_sample)):\n",
    "    article_id = row['article_id']\n",
    "    date = row['date']\n",
    "    raw_text = row['text']\n",
    "    \n",
    "    # Run your analysis\n",
    "    result = analyze_document(raw_text)\n",
    "    \n",
    "    # Handle case where result is a string (either \"NO BOOKS\" or unexpected)\n",
    "    if isinstance(result, str):\n",
    "        if result.strip().upper() == \"NO BOOKS\":\n",
    "            continue\n",
    "        else:\n",
    "            # Optional: parse the string into a DataFrame if the output is line-separated\n",
    "            # But ideally your function should return a proper DataFrame if expected\n",
    "            print(f\"Warning: Expected DataFrame but got string for article_id {article_id}\")\n",
    "            continue\n",
    "    \n",
    "    # Now we're sure result is a DataFrame — attach article_id\n",
    "    result['article_id'] = article_id\n",
    "    result['date'] = date\n",
    "    result['text'] = raw_text\n",
    "    books_dfs.append(result)\n",
    "\n",
    "# Concatenate all results\n",
    "books_df = pd.concat(books_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648c42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>translated_title</th>\n",
       "      <th>author</th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Løier Et Brev paa Vers til Joh. Nordahl Bruun</td>\n",
       "      <td>Løier A Letter in Verse to Joh. Nordahl Bruun</td>\n",
       "      <td>Niels Tønder Lund Gunnerus</td>\n",
       "      <td>lol_001393</td>\n",
       "      <td>1809-09-29</td>\n",
       "      <td>Løier Et Brev paa Vers til Joh. Nordahl Bruun,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foraaret</td>\n",
       "      <td>The Spring</td>\n",
       "      <td>James Thomson</td>\n",
       "      <td>lol_001393</td>\n",
       "      <td>1809-09-29</td>\n",
       "      <td>Løier Et Brev paa Vers til Joh. Nordahl Bruun,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>lol_001834</td>\n",
       "      <td>1809-12-12</td>\n",
       "      <td>Bekjendtgjørelser. Jndbydelse. Da udenlandske ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>lol_001987</td>\n",
       "      <td>1810-01-09</td>\n",
       "      <td>Bekjendtgjørelser. Gudstjenesten begynder 2den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>C. F. Schultz</td>\n",
       "      <td>lol_002560</td>\n",
       "      <td>1810-03-22</td>\n",
       "      <td>Disse sande skjulte Menneskevenner takkes paa ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  original_title  \\\n",
       "0  Løier Et Brev paa Vers til Joh. Nordahl Bruun   \n",
       "1                                       Foraaret   \n",
       "2                                        NO_BOOK   \n",
       "3                                        NO_BOOK   \n",
       "4                                        NO_BOOK   \n",
       "\n",
       "                                translated_title                      author  \\\n",
       "0  Løier A Letter in Verse to Joh. Nordahl Bruun  Niels Tønder Lund Gunnerus   \n",
       "1                                     The Spring               James Thomson   \n",
       "2                                        NO_BOOK                     NO_BOOK   \n",
       "3                                        NO_BOOK                     NO_BOOK   \n",
       "4                                        NO_BOOK               C. F. Schultz   \n",
       "\n",
       "   article_id        date                                               text  \n",
       "0  lol_001393  1809-09-29  Løier Et Brev paa Vers til Joh. Nordahl Bruun,...  \n",
       "1  lol_001393  1809-09-29  Løier Et Brev paa Vers til Joh. Nordahl Bruun,...  \n",
       "2  lol_001834  1809-12-12  Bekjendtgjørelser. Jndbydelse. Da udenlandske ...  \n",
       "3  lol_001987  1810-01-09  Bekjendtgjørelser. Gudstjenesten begynder 2den...  \n",
       "4  lol_002560  1810-03-22  Disse sande skjulte Menneskevenner takkes paa ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "750f9b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425, 6)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19ddbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_books = random_sample[~random_sample['article_id'].isin(books_df['article_id'])]\n",
    "no_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b55c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('../results/prompts/P3_extracted_titles_random_sample_api.csv')\n",
    "random_sample.to_csv('../results/prompts/P3_random_sample_api.csv')\n",
    "no_books[['article_id', 'text']].to_csv('../results/prompts/P3_no_books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef21279",
   "metadata": {},
   "source": [
    "### Test prompts and compare with gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f6d813e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304/174756618.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pred_df = pred_df.applymap(lambda x: str(x).strip().lower())\n",
      "/tmp/ipykernel_304/174756618.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  gold_df = gold_df.applymap(lambda x: str(x).strip().lower())\n"
     ]
    }
   ],
   "source": [
    "# Normalize and prepare\n",
    "pred_df = books_df[['article_id', 'original_title', 'author']].dropna()\n",
    "gold_df = pd.read_csv(\"../../newspaper_temp_files/training_testing_titles.csv\", index_col=0)\n",
    "gold_df = gold_df[['article_id', 'original_title', 'author']].dropna()\n",
    "\n",
    "# Lowercase and strip for comparison\n",
    "pred_df = pred_df.applymap(lambda x: str(x).strip().lower())\n",
    "gold_df = gold_df.applymap(lambda x: str(x).strip().lower())\n",
    "\n",
    "# Make sure article_id is comparable\n",
    "pred_df['article_id'] = pred_df['article_id'].astype(str)\n",
    "gold_df['article_id'] = gold_df['article_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc39a9c",
   "metadata": {},
   "source": [
    "Full match on article_id, fuzzy match on original_title and author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "486e61e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.68\n",
      "Recall:    0.71\n",
      "F1 Score:  0.70\n"
     ]
    }
   ],
   "source": [
    "FUZZY_THRESHOLD = 80\n",
    "\n",
    "matched_pred = set()\n",
    "matched_gold = set()\n",
    "\n",
    "# Join on article_id, compare title+author\n",
    "for article_id in set(pred_df['article_id']).intersection(gold_df['article_id']):\n",
    "    preds = pred_df[pred_df['article_id'] == article_id][['original_title', 'author']].values\n",
    "    golds = gold_df[gold_df['article_id'] == article_id][['original_title', 'author']].values\n",
    "\n",
    "    for pred in preds:\n",
    "        best_score = 0\n",
    "        best_gold = None\n",
    "        for gold in golds:\n",
    "            title_score = fuzz.token_sort_ratio(pred[0], gold[0])\n",
    "            author_score = fuzz.token_sort_ratio(pred[1], gold[1])\n",
    "            combined_score = (title_score + author_score) / 2\n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_gold = gold\n",
    "        if best_score >= FUZZY_THRESHOLD:\n",
    "            matched_pred.add((article_id, pred[0], pred[1]))\n",
    "            matched_gold.add((article_id, best_gold[0], best_gold[1]))\n",
    "\n",
    "# Reconstruct sets\n",
    "pred_set = set(pred_df.itertuples(index=False, name=None))\n",
    "gold_set = set(gold_df.itertuples(index=False, name=None))\n",
    "\n",
    "TP = len(matched_pred)\n",
    "FP = len(pred_set - matched_pred)\n",
    "FN = len(gold_set - matched_gold)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1 Score:  {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2a01a",
   "metadata": {},
   "source": [
    "Full match on article_id, fuzzy match on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "94adae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.79\n",
      "Recall:    0.82\n",
      "F1 Score:  0.81\n"
     ]
    }
   ],
   "source": [
    "FUZZY_THRESHOLD = 80\n",
    "\n",
    "matched_pred = set()\n",
    "matched_gold = set()\n",
    "\n",
    "# Join on article_id and fuzzy match on original_title\n",
    "for article_id in set(pred_df['article_id']).intersection(gold_df['article_id']):\n",
    "    preds = pred_df[pred_df['article_id'] == article_id]['original_title'].values\n",
    "    golds = gold_df[gold_df['article_id'] == article_id]['original_title'].values\n",
    "\n",
    "    for pred_title in preds:\n",
    "        best_score = 0\n",
    "        best_gold = None\n",
    "        for gold_title in golds:\n",
    "            score = fuzz.token_sort_ratio(pred_title, gold_title)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gold = gold_title\n",
    "        if best_score >= FUZZY_THRESHOLD:\n",
    "            matched_pred.add((article_id, pred_title))\n",
    "            matched_gold.add((article_id, best_gold))\n",
    "\n",
    "# Reconstruct sets\n",
    "pred_set = set(pred_df.itertuples(index=False, name=None))\n",
    "gold_set = set(gold_df.itertuples(index=False, name=None))\n",
    "\n",
    "# Reduce to tuples of (article_id, original_title)\n",
    "pred_set = set((row[0], row[1]) for row in pred_set)\n",
    "gold_set = set((row[0], row[1]) for row in gold_set)\n",
    "\n",
    "# Metrics\n",
    "TP = len(matched_pred)\n",
    "FP = len(pred_set - matched_pred)\n",
    "FN = len(gold_set - matched_gold)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1 Score:  {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ffa3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of false positives\n",
    "false_positives = list(pred_set - matched_pred)\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "fp_df = pd.DataFrame(false_positives, columns=['article_id', 'original_title', 'author'])\n",
    "fp_df.shape\n",
    "\n",
    "# Display or export\n",
    "#fp_df.to_csv('../results/prompts/P3_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384dc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df.to_csv('../results/prompts/P3_fp.csv')\n",
    "fn_df.to_csv('../results/prompts/P3_fn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dbe0d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of false negatives\n",
    "false_negatives = list(gold_set - matched_gold)\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "fn_df = pd.DataFrame(false_negatives, columns=['article_id', 'original_title', 'author'])\n",
    "fn_df.shape\n",
    "\n",
    "# Display or export\n",
    "#fn_df.to_csv('../results/prompts/P3_fn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a10c03",
   "metadata": {},
   "source": [
    "### Prompt improving loop (RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74258d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304/604004037.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  gold_df = gold_df[['original_title', 'author']].applymap(lambda x: str(x).strip().lower())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Iteration 1\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "📊 F1: 0.692 | Precision: 0.882 | Recall: 0.569\n",
      "📝 New prompt (start):\n",
      "Revised Prompt:\n",
      "\n",
      "\"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\n",
      "\n",
      "\"\n",
      "\"original_title: <title in Danish>\n",
      "\"\n",
      "\"translated_title: <title in English>\n",
      "\"\n",
      "\"author: <author name>\n",
      "\n",
      "\"\n",
      "\"Guidelines:\n",
      "\"\n",
      "\"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an aut...\n",
      "\n",
      "🔄 Iteration 2\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "📊 F1: 0.631 | Precision: 0.928 | Recall: 0.478\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "📝 New prompt (start):\n",
      "Revised Prompt:\n",
      "\n",
      "\"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\n",
      "\n",
      "\"\n",
      "\"original_title: <title in Danish>\n",
      "\"\n",
      "\"translated_title: <title in English>\n",
      "\"\n",
      "\"author: <author name>\n",
      "\n",
      "\"\n",
      "\"Guidelines:\n",
      "\"\n",
      "\"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an aut...\n",
      "\n",
      "🔄 Iteration 3\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "⚠️ Rate limit hit. Retrying in 1 second...\n",
      "📊 F1: 0.628 | Precision: 0.914 | Recall: 0.478\n",
      "📝 New prompt (start):\n",
      "Revised Prompt:\n",
      "\n",
      "\"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\n",
      "\n",
      "\"\n",
      "\"original_title: <title in Danish>\n",
      "\"\n",
      "\"translated_title: <title in English>\n",
      "\"\n",
      "\"author: <author name>\n",
      "\n",
      "\"\n",
      "\"Guidelines:\n",
      "\"\n",
      "\"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an aut...\n"
     ]
    }
   ],
   "source": [
    "# === Load data ===\n",
    "gold_df = pd.read_csv(\"../../newspaper_temp_files/training_testing_titles.csv\", index_col=0)\n",
    "gold_df = gold_df[['original_title', 'author']].applymap(lambda x: str(x).strip().lower())\n",
    "gold_set = set(gold_df.itertuples(index=False, name=None))\n",
    "\n",
    "sample_texts = random_sample['text'].dropna().tolist()\n",
    "\n",
    "# === OpenAI helper ===\n",
    "def call_with_retry(*args, **kwargs):\n",
    "    while True:\n",
    "        try:\n",
    "            return openai_client.chat.completions.create(*args, **kwargs)\n",
    "        except RateLimitError:\n",
    "            print(\"⚠️ Rate limit hit. Retrying in 1 second...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "# === Run GPT extraction ===\n",
    "def extract_books(prompt, text):\n",
    "    response = call_with_retry(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def parse_output(text):\n",
    "    pattern = re.compile(\n",
    "        r\"original_title:\\s*(.*?)\\ntranslated_title:\\s*(.*?)\\nauthor:\\s*(.*?)(?:\\n|$)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "    return [(m[0].strip().lower(), m[2].strip().lower()) for m in pattern.findall(text)]\n",
    "\n",
    "def run_extraction(prompt_text, sample_texts):\n",
    "    results = []\n",
    "    for text in sample_texts:\n",
    "        output = extract_books(prompt_text, text)\n",
    "        parsed = parse_output(output)\n",
    "        results.append({\n",
    "            \"input\": text,\n",
    "            \"output\": output,\n",
    "            \"parsed\": parsed\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# === Evaluate results ===\n",
    "def evaluate_results(results, gold_set):\n",
    "    pred_set = set()\n",
    "    matched_pred = set()\n",
    "    matched_gold = set()\n",
    "    tp_list = []\n",
    "    fp_list = []\n",
    "\n",
    "    for r in results:\n",
    "        for pred in r['parsed']:\n",
    "            pred_set.add(pred)\n",
    "            match, score, _ = process.extractOne(pred[0], [g[0] for g in gold_set], scorer=fuzz.token_sort_ratio)\n",
    "            if score >= 75:\n",
    "                matched_pred.add(pred)\n",
    "                matched_gold.add((match,))\n",
    "                tp_list.append(pred)\n",
    "            else:\n",
    "                fp_list.append(pred)\n",
    "\n",
    "    TP = len(tp_list)\n",
    "    FP = len(fp_list)\n",
    "    FN = len(gold_set - matched_gold)\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"precision\": round(precision, 3),\n",
    "        \"recall\": round(recall, 3),\n",
    "        \"f1\": round(f1, 3),\n",
    "        \"true_positives\": tp_list,\n",
    "        \"false_positives\": fp_list,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "# === Improve prompt ===\n",
    "def suggest_better_prompt(current_prompt, evaluation):\n",
    "    system_message = \"You are a prompt engineer. Improve prompts based on extraction results. Do not change the output format.\"\n",
    "\n",
    "    def format_examples(label, examples):\n",
    "        if not examples:\n",
    "            return f\"{label}: None\"\n",
    "        return f\"{label}:\\n\" + \"\\n\".join(f\"- Title: {title}, Author: {author}\" for title, author in examples[:5])\n",
    "\n",
    "    user_message = f\"\"\"Here is the current prompt:\n",
    "\n",
    "{current_prompt}\n",
    "\n",
    "Performance:\n",
    "- Precision: {evaluation['precision']}\n",
    "- Recall: {evaluation['recall']}\n",
    "- F1-score: {evaluation['f1']}\n",
    "\n",
    "{format_examples(\"True Positives\", evaluation['true_positives'])}\n",
    "\n",
    "{format_examples(\"False Positives\", evaluation['false_positives'])}\n",
    "\n",
    "\"Please revise this prompt to improve extraction accuracy. Keep the required output format:\\n\"\n",
    "\"original_title: <title in Danish>\\n\"\n",
    "\"translated_title: <title in English>\\n\"\n",
    "\"author: <author name>\\n\\n\"\n",
    "\n",
    "Return only the revised prompt.\n",
    "\"\"\"\n",
    "\n",
    "    response = call_with_retry(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# === Initial prompt ===\n",
    "initial_prompt = \"\"\"\n",
    "    \"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\\n\\n\"\n",
    "    \"original_title: <title in Danish>\\n\"\n",
    "    \"translated_title: <title in English>\\n\"\n",
    "    \"author: <author name>\\n\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"1. Carefully identify the beginning and end of each book title. Look for capitalization, italics, or quotation marks that may indicate a book title.\\n\"\n",
    "    \"2. If the announcement mentions multiple book titles, extract each one separately.\\n\"\n",
    "    \"3. If the author is missing or unclear, use 'NO_AUTHOR'.\\n\"\n",
    "    \"4. Translate the original Danish title into English yourself for the 'translated_title'.\\n\"\n",
    "    \"5. Pay special attention to context - announcements may contain other text (e.g., product listings, theater plays) that should not be considered book titles.\\n\"\n",
    "    \"6. If no book titles are present, return exactly one row with:\\n\"\n",
    "    \"   original_title: NO_BOOK\\n\"\n",
    "    \"   translated_title: NO_BOOK\\n\"\n",
    "    \"   author: NO_BOOK\\n\\n\"\n",
    "    \"Examples with books:\\n\"\n",
    "    \"Example1: 'Baggesens allerældste Poesier'.\\n\"\n",
    "    \"→ original_title: allerældste Poesier; translated_title: Oldest Poems; author: Baggesen\\n\"\n",
    "    \"Example2: 'Kateketisk Magasin af J. C. Wegener, Forstander for det Kongelige Skolelærer-Seminarium paa Joenstrup.'\\n\"\n",
    "    \"→ original_title: Kateketisk Magasin; translated_title: Catechetical Magazine; author: J.C. Wegener\\n\"\n",
    "    \"Example3: 'Ceres. Et periodisk Skrivt for dannede Læsere. Udgiver af F. M. Lange. Femte Hefte. Det indeholder: Juliette, eller det hemmelige Ægteskab, af Frederik Kind. - Jagtgildet, af Washington Irving. Subskription modtages hos Vogelius, Boghandler og Bogbinder.'\\n\"\n",
    "    \"→ original_title: Juliette, eller det hemmelige Ægteskab; translated_title: Juliette, or The Secret Marriage; author: Frederik Kind\\n\"\n",
    "    \"→ original_title: Jagtgildet; translated_title: The Hunting Feast; author: Washington Irving\\n\\n\"\n",
    "    \"Examples without books:\\n\"\n",
    "    \"Example1: 'J. Et Parti gode hjemmegjorte Bolster og Dynevaar er i Dag arriveret og sælges billigst muligt af M. N. Samson.'\\n\"\n",
    "    \"→ original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example2: 'C. Andersen. Første Afdeling: 'Spanierne i Odense, Vaudeville i 1 Act. Anden Afdeling: 'Fem og tyve Aar derefter i Helsingøer, Vaudeville i 1 Act. Billetter a 2 Mk. 8 s., (Børn det Halve) erholdes i mit Logie hos Hr. Kobbersmed Schmidt. Hvo som tager 6 Billetter erholder disse for 2 A. Werligh. Rbd.' This is a theater announcement.\\n\"\n",
    "    \"→ original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example3: 'Første Binds andet Hefte, indeholdende følgende Katekisationer: 1 Den ægtekristelige Menneskekjærlighed bør være ufortrøden, virksom, uegennyttig og viis 2 Om de Glæder, den sande Menneskekjærlighed skjænker os 5 Om Guds Almagt; 4 Om Guds Alvidenhed; 5 OmGuds Viisdom; 6 Til Lærebogens 6 Kap. 1. 2. 5, 7 Religion er Menneskets vigtigste Anliggende.' These are chapter titles.\\n\"\n",
    "    \"→ original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Use these guidelines and examples to enhance extraction accuracy and maintain the required output format.\\n\"\n",
    "\"\"\"\n",
    "\n",
    "# === Main loop ===\n",
    "current_prompt = initial_prompt\n",
    "history = []\n",
    "\n",
    "for i in range(3):  # Run 3 iterations\n",
    "    print(f\"\\n🔄 Iteration {i+1}\")\n",
    "\n",
    "    # Step 1: Use prompt to extract\n",
    "    results = run_extraction(current_prompt, sample_texts)\n",
    "\n",
    "    # Step 2: Evaluate\n",
    "    metrics = evaluate_results(results, gold_set)\n",
    "    print(f\"📊 F1: {metrics['f1']} | Precision: {metrics['precision']} | Recall: {metrics['recall']}\")\n",
    "\n",
    "    # Save output to file\n",
    "    pd.DataFrame(results).to_csv(f\"iteration2_{i+1}_outputs.csv\", index=False)\n",
    "\n",
    "    # Track history\n",
    "    history.append({\n",
    "        \"iteration\": i + 1,\n",
    "        \"f1\": metrics['f1'],\n",
    "        \"precision\": metrics['precision'],\n",
    "        \"recall\": metrics['recall'],\n",
    "        \"prompt\": current_prompt\n",
    "    })\n",
    "\n",
    "    # Get new prompt\n",
    "    current_prompt = suggest_better_prompt(current_prompt, metrics)\n",
    "    print(f\"📝 New prompt (start):\\n{current_prompt[:500]}...\")\n",
    "\n",
    "# === Save history ===\n",
    "pd.DataFrame(history).to_csv(\"prompt_tuning_history_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f53f6f",
   "metadata": {},
   "source": [
    "### API for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe872944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|██████████| 7531/7531 [2:04:06<00:00,  1.01it/s]  \n"
     ]
    }
   ],
   "source": [
    "# This will hold individual mini-DataFrames returned by analyze_document\n",
    "books_dfs = []\n",
    "\n",
    "for idx, row in tqdm(book_announces.iterrows(), total=len(book_announces), desc=\"Processing articles\"):\n",
    "    article_id = row['article_id']\n",
    "    date = row['date']\n",
    "    raw_text = row['text']\n",
    "    \n",
    "    # Run your analysis\n",
    "    result = analyze_document(raw_text)\n",
    "    \n",
    "    # Handle case where result is a string (either \"NO BOOKS\" or unexpected)\n",
    "    if isinstance(result, str):\n",
    "        if result.strip().upper() == \"NO BOOKS\":\n",
    "            continue\n",
    "        else:\n",
    "            # Optional: parse the string into a DataFrame if the output is line-separated\n",
    "            # But ideally your function should return a proper DataFrame if expected\n",
    "            print(f\"Warning: Expected DataFrame but got string for article_id {article_id}\")\n",
    "            continue\n",
    "    \n",
    "    # Now we're sure result is a DataFrame — attach article_id\n",
    "    result['article_id'] = article_id\n",
    "    result['date'] = date\n",
    "    result['text'] = raw_text\n",
    "    books_dfs.append(result)\n",
    "\n",
    "# Concatenate all results\n",
    "books_df = pd.concat(books_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fbf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('../results/all_extracted_titles_250530.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b27b6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10176, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76bc4f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_title\n",
       "NO_BOOK                                                                                              4127\n",
       "De vigtigste indenlandske Tildragelser og de mærkeligste Personers Levnetsbeskrivelser                 24\n",
       "Haandbog for den læsende Ungdom                                                                        22\n",
       "De mærkeligste Personers Levnetsbeskrivelse og de vigtigste Tildragelser igjennem alle Tidsaldere      17\n",
       "Nye Kogebog                                                                                            15\n",
       "Veiledning til Hovedregning eller mental Regnekunst                                                    14\n",
       "Videnskabelig Fortegnelse over Provindsialbogsamlingen i Mariboe                                       14\n",
       "Bibelske Fortællinger med Anvendelse paa Religion og Sædelære                                          13\n",
       "Thonboes Læsebog                                                                                       12\n",
       "Underviisning i Religionen for Ungdommen                                                               12\n",
       "Naturhistorie                                                                                          12\n",
       "Cramers Regnebog                                                                                       11\n",
       "Penelope                                                                                               11\n",
       "Heste og Qvæglæge Tabel                                                                                10\n",
       "Blichers Visdoms og Dyds Tabel                                                                         10\n",
       "Schous Udtog af Forordninger                                                                           10\n",
       "Digte                                                                                                  10\n",
       "De Franskes Keiser Napoleons Levnet                                                                     9\n",
       "Frierens Besøg                                                                                          9\n",
       "Haandbog for læsende Ungdom                                                                             9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df['original_title'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
