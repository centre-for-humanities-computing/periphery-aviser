{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f648763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.82.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ucloud/.local/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ucloud/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ucloud/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ucloud/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ucloud/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading openai-1.82.1-py3-none-any.whl (720 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m720.5/720.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-inspection, tqdm, threadpoolctl, rapidfuzz, pydantic-core, numpy, joblib, jiter, annotated-types, scipy, pydantic, pandas, scikit-learn, openai\n",
      "Successfully installed annotated-types-0.7.0 jiter-0.10.0 joblib-1.5.1 numpy-2.2.6 openai-1.82.1 pandas-2.2.3 pydantic-2.11.5 pydantic-core-2.33.2 pytz-2025.2 rapidfuzz-3.13.0 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0 tqdm-4.67.1 typing-inspection-0.4.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas tqdm rapidfuzz scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6389b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from rapidfuzz import fuzz, process\n",
    "import time\n",
    "from openai import RateLimitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c604eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for API keys and models\n",
    "llm_config = {\n",
    "    \"openai\": {\n",
    "        #\"api_key\": #MASKED,  # Replace with your actual API key\n",
    "        \"models\": {\n",
    "            \"default\": \"gpt-4o-mini\",\n",
    "            \"advanced\": \"gpt-4\",\n",
    "            \"economy\": \"gpt-4o-mini\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize clients with API keys from config\n",
    "# Choose which provider(s) you want to use and comment out the others if you don't have all API keys\n",
    "openai_client = OpenAI(api_key=llm_config[\"openai\"][\"api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648339f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document(document_text):\n",
    "    \"\"\"\n",
    "    Analyze a Danish 19th-century newspaper announcement and extract book titles and authors.\n",
    "\n",
    "    Args:\n",
    "        document_text (str): The text of the document to analyze.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame or str: DataFrame with extracted entities or 'NO BOOKS'.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "    \"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\\n\\n\"\n",
    "    \"original_title: <title in Danish>\\n\"\n",
    "    \"translated_title: <title in English>\\n\"\n",
    "    \"author: <author name>\\n\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an author‚Äôs name.\\n\"\n",
    "    \"2. If the announcement mentions multiple book titles, extract each one separately. Ensure each title is uniquely identified.\\n\"\n",
    "    \"3. If the author is missing or unclear, use 'NO_AUTHOR'. Verify the context to ensure the correct identification of authors.\\n\"\n",
    "    \"4. Translate the original Danish title into English yourself for the 'translated_title'. Ensure the translation preserves the meaning and context of the original title.\\n\"\n",
    "    \"5. Pay special attention to context - announcements may contain other text (e.g., product listings, theater plays, chapter titles) that should not be considered book titles. Identify keywords that separate book titles from other content.\\n\"\n",
    "    \"6. If no book titles are present, return exactly one row with:\\n\"\n",
    "    \"   original_title: NO_BOOK\\n\"\n",
    "    \"   translated_title: NO_BOOK\\n\"\n",
    "    \"   author: NO_BOOK\\n\\n\"\n",
    "    \"Examples with books:\\n\"\n",
    "    \"Example1: 'Baggesens aller√¶ldste Poesier'.\\n\"\n",
    "    \"‚Üí original_title: aller√¶ldste Poesier; translated_title: Oldest Poems; author: Baggesen\\n\"\n",
    "    \"Example2: 'Kateketisk Magasin af J. C. Wegener, Forstander for det Kongelige Skolel√¶rer-Seminarium paa Joenstrup.'\\n\"\n",
    "    \"‚Üí original_title: Kateketisk Magasin; translated_title: Catechetical Magazine; author: J.C. Wegener\\n\"\n",
    "    \"Example3: 'Ceres. Et periodisk Skrivt for dannede L√¶sere. Udgiver af F. M. Lange. Femte Hefte. Det indeholder: Juliette, eller det hemmelige √Ügteskab, af Frederik Kind. - Jagtgildet, af Washington Irving. Subskription modtages hos Vogelius, Boghandler og Bogbinder.'\\n\"\n",
    "    \"‚Üí original_title: Juliette, eller det hemmelige √Ügteskab; translated_title: Juliette, or The Secret Marriage; author: Frederik Kind\\n\"\n",
    "    \"‚Üí original_title: Jagtgildet; translated_title: The Hunting Feast; author: Washington Irving\\n\\n\"\n",
    "    \"Examples without books:\\n\"\n",
    "    \"Example1: 'J. Et Parti gode hjemmegjorte Bolster og Dynevaar er i Dag arriveret og s√¶lges billigst muligt af M. N. Samson.'\\n\"\n",
    "    \"‚Üí original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example2: 'C. Andersen. F√∏rste Afdeling: 'Spanierne i Odense, Vaudeville i 1 Act. Anden Afdeling: 'Fem og tyve Aar derefter i Helsing√∏er, Vaudeville i 1 Act. Billetter a 2 Mk. 8 s., (B√∏rn det Halve) erholdes i mit Logie hos Hr. Kobbersmed Schmidt. Hvo som tager 6 Billetter erholder disse for 2 A. Werligh. Rbd.' This is a theater announcement.\\n\"\n",
    "    \"‚Üí original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example3: 'F√∏rste Binds andet Hefte, indeholdende f√∏lgende Katekisationer: 1 Den √¶gtekristelige Menneskekj√¶rlighed b√∏r v√¶re ufortr√∏den, virksom, uegennyttig og viis 2 Om de Gl√¶der, den sande Menneskekj√¶rlighed skj√¶nker os 5 Om Guds Almagt; 4 Om Guds Alvidenhed; 5 OmGuds Viisdom; 6 Til L√¶rebogens 6 Kap. 1. 2. 5, 7 Religion er Menneskets vigtigste Anliggende.' These are chapter titles.\\n\"\n",
    "    \"‚Üí original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Use these guidelines and examples to enhance extraction accuracy and maintain the required output format.\\n\"\n",
    ")\n",
    "\n",
    "    try:\n",
    "        model = llm_config[\"openai\"][\"models\"][\"default\"]\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": document_text}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=800\n",
    "        )\n",
    "\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        if result_text.upper() == \"NO BOOKS\":\n",
    "            return \"NO BOOKS\"\n",
    "\n",
    "        # Extract structured results\n",
    "        pattern = re.compile(\n",
    "            r\"original_title:\\s*(.*?)\\ntranslated_title:\\s*(.*?)\\nauthor:\\s*(.*?)(?:\\n|$)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        entries = [\n",
    "            {\n",
    "                \"original_title\": match.group(1).strip(),\n",
    "                \"translated_title\": match.group(2).strip(),\n",
    "                \"author\": match.group(3).strip()\n",
    "            }\n",
    "            for match in pattern.finditer(result_text)\n",
    "        ]\n",
    "\n",
    "        return pd.DataFrame(entries)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing document with OpenAI: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd85656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI BOOK TITLE EXTRACTION:\n",
      "                                   original_title  \\\n",
      "0                 Niels Klims underjordiske Reise   \n",
      "1  Opfordring til Lollands og Falsters Jndbyggere   \n",
      "2                                         NO_BOOK   \n",
      "\n",
      "                                   translated_title          author  \n",
      "0                  Niels Klim's Underground Journey      L. Holberg  \n",
      "1  Appeal to the Inhabitants of Lolland and Falster  K. H. Seidelin  \n",
      "2                                           NO_BOOK         NO_BOOK  \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage in a notebook\n",
    "sample_document = \"\"\"\n",
    "Paa Addresse-Contoiret i Mariboe er pr. Commission til Salg et nitid Exemplar af Pragt-Udgaven af Niels Klims underjordiske Reise ved L. Holberg. Oversat efter den lanske Original af Jens Baggesen Kbh. 1789, m. sine Kobb. Prisen er 4 Rd. D. C. Hr. Lientenant K. H. Seidelins Opfordring til Lollands og Falsters Jndbyggere, at tilberede raae Salpeter, med Prosessor Maschmanns Underretning om Salpeters Tilvirkning, kan paa Addresse-Contoiret. i Mariboe bekommes gratis.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"OPENAI BOOK TITLE EXTRACTION:\")\n",
    "openai_summary = analyze_document(sample_document)\n",
    "print(openai_summary)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf2a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "      <th>n_chunks_orig</th>\n",
       "      <th>clean_category</th>\n",
       "      <th>n√∏gle</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>article_length</th>\n",
       "      <th>characters</th>\n",
       "      <th>embedding_shape</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>label_type</th>\n",
       "      <th>book_announce</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_book_announce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lol_000038</td>\n",
       "      <td>1809-03-07</td>\n",
       "      <td>[ 0.03518467  0.00932873 -0.0178937  ... -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-03-07_52</td>\n",
       "      <td>Paa Addresse-Contoiret i Mariboe bekommes f√∏lg...</td>\n",
       "      <td>Bekiendtgi√∏relser</td>\n",
       "      <td>76</td>\n",
       "      <td>475</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>lol_000109</td>\n",
       "      <td>1809-03-17</td>\n",
       "      <td>[ 0.02211799  0.00355701 -0.02588731 ... -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-03-17_174</td>\n",
       "      <td>Maskeradeballet i Dannemark 1808. Et Syn af N....</td>\n",
       "      <td>Bekiendtgi√∏relser</td>\n",
       "      <td>84</td>\n",
       "      <td>495</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>lol_000189</td>\n",
       "      <td>1809-03-28</td>\n",
       "      <td>[ 0.04022709  0.02202421 -0.01741452 ... -0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-03-28_306</td>\n",
       "      <td>Maskeradeballet i Dannemark 1808. Et Syn af N....</td>\n",
       "      <td>Bekiendtgi√∏relser</td>\n",
       "      <td>29</td>\n",
       "      <td>148</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>lol_000330</td>\n",
       "      <td>1809-04-18</td>\n",
       "      <td>[ 0.02150071  0.00016588 -0.00461735 ... -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-04-18_554</td>\n",
       "      <td>Alle Slags Bogbinder-Arbeide, saavel nyt, som ...</td>\n",
       "      <td>Bekiendtgi√∏relser</td>\n",
       "      <td>50</td>\n",
       "      <td>341</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>lol_000476</td>\n",
       "      <td>1809-05-09</td>\n",
       "      <td>[ 0.0191186   0.00117065 -0.01776858 ... -0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-05-09_826</td>\n",
       "      <td>Paa Addresse-Contoiret i Mariboe er pr. Commis...</td>\n",
       "      <td>Bekiendtgi√∏relser</td>\n",
       "      <td>70</td>\n",
       "      <td>469</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id        date  \\\n",
       "37   lol_000038  1809-03-07   \n",
       "108  lol_000109  1809-03-17   \n",
       "188  lol_000189  1809-03-28   \n",
       "328  lol_000330  1809-04-18   \n",
       "470  lol_000476  1809-05-09   \n",
       "\n",
       "                                             embedding  n_chunks_orig  \\\n",
       "37   [ 0.03518467  0.00932873 -0.0178937  ... -0.02...              1   \n",
       "108  [ 0.02211799  0.00355701 -0.02588731 ... -0.00...              1   \n",
       "188  [ 0.04022709  0.02202421 -0.01741452 ... -0.01...              1   \n",
       "328  [ 0.02150071  0.00016588 -0.00461735 ... -0.02...              1   \n",
       "470  [ 0.0191186   0.00117065 -0.01776858 ... -0.03...              1   \n",
       "\n",
       "        clean_category           n√∏gle  \\\n",
       "37   Bekjendtgj√∏relser   1809-03-07_52   \n",
       "108  Bekjendtgj√∏relser  1809-03-17_174   \n",
       "188  Bekjendtgj√∏relser  1809-03-28_306   \n",
       "328  Bekjendtgj√∏relser  1809-04-18_554   \n",
       "470  Bekjendtgj√∏relser  1809-05-09_826   \n",
       "\n",
       "                                                  text           category  \\\n",
       "37   Paa Addresse-Contoiret i Mariboe bekommes f√∏lg...  Bekiendtgi√∏relser   \n",
       "108  Maskeradeballet i Dannemark 1808. Et Syn af N....  Bekiendtgi√∏relser   \n",
       "188  Maskeradeballet i Dannemark 1808. Et Syn af N....  Bekiendtgi√∏relser   \n",
       "328  Alle Slags Bogbinder-Arbeide, saavel nyt, som ...  Bekiendtgi√∏relser   \n",
       "470  Paa Addresse-Contoiret i Mariboe er pr. Commis...  Bekiendtgi√∏relser   \n",
       "\n",
       "     article_length  characters embedding_shape newspaper label_type  \\\n",
       "37               76         475          [1024]       lol       gold   \n",
       "108              84         495          [1024]       lol       gold   \n",
       "188              29         148          [1024]       lol       gold   \n",
       "328              50         341          [1024]       lol       gold   \n",
       "470              70         469          [1024]       lol       gold   \n",
       "\n",
       "    book_announce comment predicted_book_announce  \n",
       "37        unknown     NaN                       y  \n",
       "108       unknown     NaN                       y  \n",
       "188       unknown     NaN                       y  \n",
       "328       unknown     NaN                       y  \n",
       "470       unknown     NaN                       y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load book announcements\n",
    "book_announces = pd.read_csv('../data/book_announces_250503.csv', index_col=0)\n",
    "book_announces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c9b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample with the gold standard articles\n",
    "\n",
    "gold_df = pd.read_csv(\"../../newspaper_temp_files/training_testing_titles.csv\", index_col=0)\n",
    "\n",
    "random_sample = book_announces[book_announces['article_id'].isin(gold_df['article_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb3b0dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "      <th>n_chunks_orig</th>\n",
       "      <th>clean_category</th>\n",
       "      <th>n√∏gle</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>article_length</th>\n",
       "      <th>characters</th>\n",
       "      <th>embedding_shape</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>label_type</th>\n",
       "      <th>book_announce</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_book_announce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>lol_001393</td>\n",
       "      <td>1809-09-29</td>\n",
       "      <td>[ 0.05600849  0.01557517 -0.02665625 ... -0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-09-29_2574</td>\n",
       "      <td>L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun,...</td>\n",
       "      <td>Bekiendtgi√∏relser</td>\n",
       "      <td>33</td>\n",
       "      <td>185</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>lol_001834</td>\n",
       "      <td>1809-12-12</td>\n",
       "      <td>[ 0.01884314  0.02579251  0.0012215  ... -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1809-12-12_3367</td>\n",
       "      <td>Bekjendtgj√∏relser. Jndbydelse. Da udenlandske ...</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>45</td>\n",
       "      <td>296</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>lol_001987</td>\n",
       "      <td>1810-01-09</td>\n",
       "      <td>[ 0.03172351  0.02591745 -0.00467053 ... -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1810-01-09_3675</td>\n",
       "      <td>Bekjendtgj√∏relser. Gudstjenesten begynder 2den...</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>30</td>\n",
       "      <td>196</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>lol_002560</td>\n",
       "      <td>1810-03-22</td>\n",
       "      <td>[-0.00690638  0.02288655 -0.03385538 ...  0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1810-03-22_4723</td>\n",
       "      <td>Disse sande skjulte Menneskevenner takkes paa ...</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>lol_003135</td>\n",
       "      <td>1810-06-05</td>\n",
       "      <td>[ 0.03199682  0.00117054 -0.01987574 ... -0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>1810-06-05_5778</td>\n",
       "      <td>Tanker i Anledning af Skrivelsen fra Falster, ...</td>\n",
       "      <td>Bekjendtgj√∏relser</td>\n",
       "      <td>22</td>\n",
       "      <td>130</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>lol</td>\n",
       "      <td>gold</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id        date  \\\n",
       "1382  lol_001393  1809-09-29   \n",
       "1822  lol_001834  1809-12-12   \n",
       "1975  lol_001987  1810-01-09   \n",
       "2547  lol_002560  1810-03-22   \n",
       "3121  lol_003135  1810-06-05   \n",
       "\n",
       "                                              embedding  n_chunks_orig  \\\n",
       "1382  [ 0.05600849  0.01557517 -0.02665625 ... -0.03...              1   \n",
       "1822  [ 0.01884314  0.02579251  0.0012215  ... -0.02...              1   \n",
       "1975  [ 0.03172351  0.02591745 -0.00467053 ... -0.00...              1   \n",
       "2547  [-0.00690638  0.02288655 -0.03385538 ...  0.00...              1   \n",
       "3121  [ 0.03199682  0.00117054 -0.01987574 ... -0.01...              1   \n",
       "\n",
       "         clean_category            n√∏gle  \\\n",
       "1382  Bekjendtgj√∏relser  1809-09-29_2574   \n",
       "1822  Bekjendtgj√∏relser  1809-12-12_3367   \n",
       "1975  Bekjendtgj√∏relser  1810-01-09_3675   \n",
       "2547  Bekjendtgj√∏relser  1810-03-22_4723   \n",
       "3121  Bekjendtgj√∏relser  1810-06-05_5778   \n",
       "\n",
       "                                                   text           category  \\\n",
       "1382  L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun,...  Bekiendtgi√∏relser   \n",
       "1822  Bekjendtgj√∏relser. Jndbydelse. Da udenlandske ...  Bekjendtgj√∏relser   \n",
       "1975  Bekjendtgj√∏relser. Gudstjenesten begynder 2den...  Bekjendtgj√∏relser   \n",
       "2547  Disse sande skjulte Menneskevenner takkes paa ...  Bekjendtgj√∏relser   \n",
       "3121  Tanker i Anledning af Skrivelsen fra Falster, ...  Bekjendtgj√∏relser   \n",
       "\n",
       "      article_length  characters embedding_shape newspaper label_type  \\\n",
       "1382              33         185          [1024]       lol       gold   \n",
       "1822              45         296          [1024]       lol       gold   \n",
       "1975              30         196          [1024]       lol       gold   \n",
       "2547              12          79          [1024]       lol       gold   \n",
       "3121              22         130          [1024]       lol       gold   \n",
       "\n",
       "     book_announce comment predicted_book_announce  \n",
       "1382       unknown     NaN                       y  \n",
       "1822       unknown     NaN                       y  \n",
       "1975       unknown     NaN                       y  \n",
       "2547       unknown     NaN                       y  \n",
       "3121       unknown     NaN                       y  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3db49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random sample\n",
    "\n",
    "#random_sample = book_announces.sample(n=300, random_state=42)\n",
    "\n",
    "#random_sample = book_announces.groupby('newspaper').sample(n=50, random_state=42)\n",
    "#random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a143a0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [05:34<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# This will hold individual mini-DataFrames returned by analyze_document\n",
    "books_dfs = []\n",
    "\n",
    "for idx, row in tqdm(random_sample.iterrows(), total=len(random_sample)):\n",
    "    article_id = row['article_id']\n",
    "    date = row['date']\n",
    "    raw_text = row['text']\n",
    "    \n",
    "    # Run your analysis\n",
    "    result = analyze_document(raw_text)\n",
    "    \n",
    "    # Handle case where result is a string (either \"NO BOOKS\" or unexpected)\n",
    "    if isinstance(result, str):\n",
    "        if result.strip().upper() == \"NO BOOKS\":\n",
    "            continue\n",
    "        else:\n",
    "            # Optional: parse the string into a DataFrame if the output is line-separated\n",
    "            # But ideally your function should return a proper DataFrame if expected\n",
    "            print(f\"Warning: Expected DataFrame but got string for article_id {article_id}\")\n",
    "            continue\n",
    "    \n",
    "    # Now we're sure result is a DataFrame ‚Äî attach article_id\n",
    "    result['article_id'] = article_id\n",
    "    result['date'] = date\n",
    "    result['text'] = raw_text\n",
    "    books_dfs.append(result)\n",
    "\n",
    "# Concatenate all results\n",
    "books_df = pd.concat(books_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648c42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>translated_title</th>\n",
       "      <th>author</th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun</td>\n",
       "      <td>L√∏ier A Letter in Verse to Joh. Nordahl Bruun</td>\n",
       "      <td>Niels T√∏nder Lund Gunnerus</td>\n",
       "      <td>lol_001393</td>\n",
       "      <td>1809-09-29</td>\n",
       "      <td>L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foraaret</td>\n",
       "      <td>The Spring</td>\n",
       "      <td>James Thomson</td>\n",
       "      <td>lol_001393</td>\n",
       "      <td>1809-09-29</td>\n",
       "      <td>L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>lol_001834</td>\n",
       "      <td>1809-12-12</td>\n",
       "      <td>Bekjendtgj√∏relser. Jndbydelse. Da udenlandske ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>lol_001987</td>\n",
       "      <td>1810-01-09</td>\n",
       "      <td>Bekjendtgj√∏relser. Gudstjenesten begynder 2den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>NO_BOOK</td>\n",
       "      <td>C. F. Schultz</td>\n",
       "      <td>lol_002560</td>\n",
       "      <td>1810-03-22</td>\n",
       "      <td>Disse sande skjulte Menneskevenner takkes paa ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  original_title  \\\n",
       "0  L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun   \n",
       "1                                       Foraaret   \n",
       "2                                        NO_BOOK   \n",
       "3                                        NO_BOOK   \n",
       "4                                        NO_BOOK   \n",
       "\n",
       "                                translated_title                      author  \\\n",
       "0  L√∏ier A Letter in Verse to Joh. Nordahl Bruun  Niels T√∏nder Lund Gunnerus   \n",
       "1                                     The Spring               James Thomson   \n",
       "2                                        NO_BOOK                     NO_BOOK   \n",
       "3                                        NO_BOOK                     NO_BOOK   \n",
       "4                                        NO_BOOK               C. F. Schultz   \n",
       "\n",
       "   article_id        date                                               text  \n",
       "0  lol_001393  1809-09-29  L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun,...  \n",
       "1  lol_001393  1809-09-29  L√∏ier Et Brev paa Vers til Joh. Nordahl Bruun,...  \n",
       "2  lol_001834  1809-12-12  Bekjendtgj√∏relser. Jndbydelse. Da udenlandske ...  \n",
       "3  lol_001987  1810-01-09  Bekjendtgj√∏relser. Gudstjenesten begynder 2den...  \n",
       "4  lol_002560  1810-03-22  Disse sande skjulte Menneskevenner takkes paa ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "750f9b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425, 6)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19ddbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_books = random_sample[~random_sample['article_id'].isin(books_df['article_id'])]\n",
    "no_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b55c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('../results/prompts/P3_extracted_titles_random_sample_api.csv')\n",
    "random_sample.to_csv('../results/prompts/P3_random_sample_api.csv')\n",
    "no_books[['article_id', 'text']].to_csv('../results/prompts/P3_no_books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef21279",
   "metadata": {},
   "source": [
    "### Test prompts and compare with gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f6d813e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304/174756618.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pred_df = pred_df.applymap(lambda x: str(x).strip().lower())\n",
      "/tmp/ipykernel_304/174756618.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  gold_df = gold_df.applymap(lambda x: str(x).strip().lower())\n"
     ]
    }
   ],
   "source": [
    "# Normalize and prepare\n",
    "pred_df = books_df[['article_id', 'original_title', 'author']].dropna()\n",
    "gold_df = pd.read_csv(\"../../newspaper_temp_files/training_testing_titles.csv\", index_col=0)\n",
    "gold_df = gold_df[['article_id', 'original_title', 'author']].dropna()\n",
    "\n",
    "# Lowercase and strip for comparison\n",
    "pred_df = pred_df.applymap(lambda x: str(x).strip().lower())\n",
    "gold_df = gold_df.applymap(lambda x: str(x).strip().lower())\n",
    "\n",
    "# Make sure article_id is comparable\n",
    "pred_df['article_id'] = pred_df['article_id'].astype(str)\n",
    "gold_df['article_id'] = gold_df['article_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc39a9c",
   "metadata": {},
   "source": [
    "Full match on article_id, fuzzy match on original_title and author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "486e61e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.68\n",
      "Recall:    0.71\n",
      "F1 Score:  0.70\n"
     ]
    }
   ],
   "source": [
    "FUZZY_THRESHOLD = 80\n",
    "\n",
    "matched_pred = set()\n",
    "matched_gold = set()\n",
    "\n",
    "# Join on article_id, compare title+author\n",
    "for article_id in set(pred_df['article_id']).intersection(gold_df['article_id']):\n",
    "    preds = pred_df[pred_df['article_id'] == article_id][['original_title', 'author']].values\n",
    "    golds = gold_df[gold_df['article_id'] == article_id][['original_title', 'author']].values\n",
    "\n",
    "    for pred in preds:\n",
    "        best_score = 0\n",
    "        best_gold = None\n",
    "        for gold in golds:\n",
    "            title_score = fuzz.token_sort_ratio(pred[0], gold[0])\n",
    "            author_score = fuzz.token_sort_ratio(pred[1], gold[1])\n",
    "            combined_score = (title_score + author_score) / 2\n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_gold = gold\n",
    "        if best_score >= FUZZY_THRESHOLD:\n",
    "            matched_pred.add((article_id, pred[0], pred[1]))\n",
    "            matched_gold.add((article_id, best_gold[0], best_gold[1]))\n",
    "\n",
    "# Reconstruct sets\n",
    "pred_set = set(pred_df.itertuples(index=False, name=None))\n",
    "gold_set = set(gold_df.itertuples(index=False, name=None))\n",
    "\n",
    "TP = len(matched_pred)\n",
    "FP = len(pred_set - matched_pred)\n",
    "FN = len(gold_set - matched_gold)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1 Score:  {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2a01a",
   "metadata": {},
   "source": [
    "Full match on article_id, fuzzy match on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "94adae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.79\n",
      "Recall:    0.82\n",
      "F1 Score:  0.81\n"
     ]
    }
   ],
   "source": [
    "FUZZY_THRESHOLD = 80\n",
    "\n",
    "matched_pred = set()\n",
    "matched_gold = set()\n",
    "\n",
    "# Join on article_id and fuzzy match on original_title\n",
    "for article_id in set(pred_df['article_id']).intersection(gold_df['article_id']):\n",
    "    preds = pred_df[pred_df['article_id'] == article_id]['original_title'].values\n",
    "    golds = gold_df[gold_df['article_id'] == article_id]['original_title'].values\n",
    "\n",
    "    for pred_title in preds:\n",
    "        best_score = 0\n",
    "        best_gold = None\n",
    "        for gold_title in golds:\n",
    "            score = fuzz.token_sort_ratio(pred_title, gold_title)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gold = gold_title\n",
    "        if best_score >= FUZZY_THRESHOLD:\n",
    "            matched_pred.add((article_id, pred_title))\n",
    "            matched_gold.add((article_id, best_gold))\n",
    "\n",
    "# Reconstruct sets\n",
    "pred_set = set(pred_df.itertuples(index=False, name=None))\n",
    "gold_set = set(gold_df.itertuples(index=False, name=None))\n",
    "\n",
    "# Reduce to tuples of (article_id, original_title)\n",
    "pred_set = set((row[0], row[1]) for row in pred_set)\n",
    "gold_set = set((row[0], row[1]) for row in gold_set)\n",
    "\n",
    "# Metrics\n",
    "TP = len(matched_pred)\n",
    "FP = len(pred_set - matched_pred)\n",
    "FN = len(gold_set - matched_gold)\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1 Score:  {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ffa3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of false positives\n",
    "false_positives = list(pred_set - matched_pred)\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "fp_df = pd.DataFrame(false_positives, columns=['article_id', 'original_title', 'author'])\n",
    "fp_df.shape\n",
    "\n",
    "# Display or export\n",
    "#fp_df.to_csv('../results/prompts/P3_fp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384dc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df.to_csv('../results/prompts/P3_fp.csv')\n",
    "fn_df.to_csv('../results/prompts/P3_fn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dbe0d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of false negatives\n",
    "false_negatives = list(gold_set - matched_gold)\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "fn_df = pd.DataFrame(false_negatives, columns=['article_id', 'original_title', 'author'])\n",
    "fn_df.shape\n",
    "\n",
    "# Display or export\n",
    "#fn_df.to_csv('../results/prompts/P3_fn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a10c03",
   "metadata": {},
   "source": [
    "### Prompt improving loop (RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74258d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304/604004037.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  gold_df = gold_df[['original_title', 'author']].applymap(lambda x: str(x).strip().lower())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Iteration 1\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "üìä F1: 0.692 | Precision: 0.882 | Recall: 0.569\n",
      "üìù New prompt (start):\n",
      "Revised Prompt:\n",
      "\n",
      "\"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\n",
      "\n",
      "\"\n",
      "\"original_title: <title in Danish>\n",
      "\"\n",
      "\"translated_title: <title in English>\n",
      "\"\n",
      "\"author: <author name>\n",
      "\n",
      "\"\n",
      "\"Guidelines:\n",
      "\"\n",
      "\"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an aut...\n",
      "\n",
      "üîÑ Iteration 2\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "üìä F1: 0.631 | Precision: 0.928 | Recall: 0.478\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "üìù New prompt (start):\n",
      "Revised Prompt:\n",
      "\n",
      "\"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\n",
      "\n",
      "\"\n",
      "\"original_title: <title in Danish>\n",
      "\"\n",
      "\"translated_title: <title in English>\n",
      "\"\n",
      "\"author: <author name>\n",
      "\n",
      "\"\n",
      "\"Guidelines:\n",
      "\"\n",
      "\"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an aut...\n",
      "\n",
      "üîÑ Iteration 3\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\n",
      "üìä F1: 0.628 | Precision: 0.914 | Recall: 0.478\n",
      "üìù New prompt (start):\n",
      "Revised Prompt:\n",
      "\n",
      "\"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\n",
      "\n",
      "\"\n",
      "\"original_title: <title in Danish>\n",
      "\"\n",
      "\"translated_title: <title in English>\n",
      "\"\n",
      "\"author: <author name>\n",
      "\n",
      "\"\n",
      "\"Guidelines:\n",
      "\"\n",
      "\"1. Carefully identify the beginning and end of each book title. Pay attention to capitalization, italics, quotation marks, or context that may indicate a book title. Titles are often followed by a description or an aut...\n"
     ]
    }
   ],
   "source": [
    "# === Load data ===\n",
    "gold_df = pd.read_csv(\"../../newspaper_temp_files/training_testing_titles.csv\", index_col=0)\n",
    "gold_df = gold_df[['original_title', 'author']].applymap(lambda x: str(x).strip().lower())\n",
    "gold_set = set(gold_df.itertuples(index=False, name=None))\n",
    "\n",
    "sample_texts = random_sample['text'].dropna().tolist()\n",
    "\n",
    "# === OpenAI helper ===\n",
    "def call_with_retry(*args, **kwargs):\n",
    "    while True:\n",
    "        try:\n",
    "            return openai_client.chat.completions.create(*args, **kwargs)\n",
    "        except RateLimitError:\n",
    "            print(\"‚ö†Ô∏è Rate limit hit. Retrying in 1 second...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "# === Run GPT extraction ===\n",
    "def extract_books(prompt, text):\n",
    "    response = call_with_retry(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def parse_output(text):\n",
    "    pattern = re.compile(\n",
    "        r\"original_title:\\s*(.*?)\\ntranslated_title:\\s*(.*?)\\nauthor:\\s*(.*?)(?:\\n|$)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "    return [(m[0].strip().lower(), m[2].strip().lower()) for m in pattern.findall(text)]\n",
    "\n",
    "def run_extraction(prompt_text, sample_texts):\n",
    "    results = []\n",
    "    for text in sample_texts:\n",
    "        output = extract_books(prompt_text, text)\n",
    "        parsed = parse_output(output)\n",
    "        results.append({\n",
    "            \"input\": text,\n",
    "            \"output\": output,\n",
    "            \"parsed\": parsed\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# === Evaluate results ===\n",
    "def evaluate_results(results, gold_set):\n",
    "    pred_set = set()\n",
    "    matched_pred = set()\n",
    "    matched_gold = set()\n",
    "    tp_list = []\n",
    "    fp_list = []\n",
    "\n",
    "    for r in results:\n",
    "        for pred in r['parsed']:\n",
    "            pred_set.add(pred)\n",
    "            match, score, _ = process.extractOne(pred[0], [g[0] for g in gold_set], scorer=fuzz.token_sort_ratio)\n",
    "            if score >= 75:\n",
    "                matched_pred.add(pred)\n",
    "                matched_gold.add((match,))\n",
    "                tp_list.append(pred)\n",
    "            else:\n",
    "                fp_list.append(pred)\n",
    "\n",
    "    TP = len(tp_list)\n",
    "    FP = len(fp_list)\n",
    "    FN = len(gold_set - matched_gold)\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"precision\": round(precision, 3),\n",
    "        \"recall\": round(recall, 3),\n",
    "        \"f1\": round(f1, 3),\n",
    "        \"true_positives\": tp_list,\n",
    "        \"false_positives\": fp_list,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "# === Improve prompt ===\n",
    "def suggest_better_prompt(current_prompt, evaluation):\n",
    "    system_message = \"You are a prompt engineer. Improve prompts based on extraction results. Do not change the output format.\"\n",
    "\n",
    "    def format_examples(label, examples):\n",
    "        if not examples:\n",
    "            return f\"{label}: None\"\n",
    "        return f\"{label}:\\n\" + \"\\n\".join(f\"- Title: {title}, Author: {author}\" for title, author in examples[:5])\n",
    "\n",
    "    user_message = f\"\"\"Here is the current prompt:\n",
    "\n",
    "{current_prompt}\n",
    "\n",
    "Performance:\n",
    "- Precision: {evaluation['precision']}\n",
    "- Recall: {evaluation['recall']}\n",
    "- F1-score: {evaluation['f1']}\n",
    "\n",
    "{format_examples(\"True Positives\", evaluation['true_positives'])}\n",
    "\n",
    "{format_examples(\"False Positives\", evaluation['false_positives'])}\n",
    "\n",
    "\"Please revise this prompt to improve extraction accuracy. Keep the required output format:\\n\"\n",
    "\"original_title: <title in Danish>\\n\"\n",
    "\"translated_title: <title in English>\\n\"\n",
    "\"author: <author name>\\n\\n\"\n",
    "\n",
    "Return only the revised prompt.\n",
    "\"\"\"\n",
    "\n",
    "    response = call_with_retry(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# === Initial prompt ===\n",
    "initial_prompt = \"\"\"\n",
    "    \"Here is an announcement in a Danish nineteenth-century newspaper. Your task is to extract book titles and authors using the following format:\\n\\n\"\n",
    "    \"original_title: <title in Danish>\\n\"\n",
    "    \"translated_title: <title in English>\\n\"\n",
    "    \"author: <author name>\\n\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"1. Carefully identify the beginning and end of each book title. Look for capitalization, italics, or quotation marks that may indicate a book title.\\n\"\n",
    "    \"2. If the announcement mentions multiple book titles, extract each one separately.\\n\"\n",
    "    \"3. If the author is missing or unclear, use 'NO_AUTHOR'.\\n\"\n",
    "    \"4. Translate the original Danish title into English yourself for the 'translated_title'.\\n\"\n",
    "    \"5. Pay special attention to context - announcements may contain other text (e.g., product listings, theater plays) that should not be considered book titles.\\n\"\n",
    "    \"6. If no book titles are present, return exactly one row with:\\n\"\n",
    "    \"   original_title: NO_BOOK\\n\"\n",
    "    \"   translated_title: NO_BOOK\\n\"\n",
    "    \"   author: NO_BOOK\\n\\n\"\n",
    "    \"Examples with books:\\n\"\n",
    "    \"Example1: 'Baggesens aller√¶ldste Poesier'.\\n\"\n",
    "    \"‚Üí original_title: aller√¶ldste Poesier; translated_title: Oldest Poems; author: Baggesen\\n\"\n",
    "    \"Example2: 'Kateketisk Magasin af J. C. Wegener, Forstander for det Kongelige Skolel√¶rer-Seminarium paa Joenstrup.'\\n\"\n",
    "    \"‚Üí original_title: Kateketisk Magasin; translated_title: Catechetical Magazine; author: J.C. Wegener\\n\"\n",
    "    \"Example3: 'Ceres. Et periodisk Skrivt for dannede L√¶sere. Udgiver af F. M. Lange. Femte Hefte. Det indeholder: Juliette, eller det hemmelige √Ügteskab, af Frederik Kind. - Jagtgildet, af Washington Irving. Subskription modtages hos Vogelius, Boghandler og Bogbinder.'\\n\"\n",
    "    \"‚Üí original_title: Juliette, eller det hemmelige √Ügteskab; translated_title: Juliette, or The Secret Marriage; author: Frederik Kind\\n\"\n",
    "    \"‚Üí original_title: Jagtgildet; translated_title: The Hunting Feast; author: Washington Irving\\n\\n\"\n",
    "    \"Examples without books:\\n\"\n",
    "    \"Example1: 'J. Et Parti gode hjemmegjorte Bolster og Dynevaar er i Dag arriveret og s√¶lges billigst muligt af M. N. Samson.'\\n\"\n",
    "    \"‚Üí original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example2: 'C. Andersen. F√∏rste Afdeling: 'Spanierne i Odense, Vaudeville i 1 Act. Anden Afdeling: 'Fem og tyve Aar derefter i Helsing√∏er, Vaudeville i 1 Act. Billetter a 2 Mk. 8 s., (B√∏rn det Halve) erholdes i mit Logie hos Hr. Kobbersmed Schmidt. Hvo som tager 6 Billetter erholder disse for 2 A. Werligh. Rbd.' This is a theater announcement.\\n\"\n",
    "    \"‚Üí original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Example3: 'F√∏rste Binds andet Hefte, indeholdende f√∏lgende Katekisationer: 1 Den √¶gtekristelige Menneskekj√¶rlighed b√∏r v√¶re ufortr√∏den, virksom, uegennyttig og viis 2 Om de Gl√¶der, den sande Menneskekj√¶rlighed skj√¶nker os 5 Om Guds Almagt; 4 Om Guds Alvidenhed; 5 OmGuds Viisdom; 6 Til L√¶rebogens 6 Kap. 1. 2. 5, 7 Religion er Menneskets vigtigste Anliggende.' These are chapter titles.\\n\"\n",
    "    \"‚Üí original_title: NO_BOOK; translated_title: NO_BOOK; author: NO_BOOK\\n\"\n",
    "    \"Use these guidelines and examples to enhance extraction accuracy and maintain the required output format.\\n\"\n",
    "\"\"\"\n",
    "\n",
    "# === Main loop ===\n",
    "current_prompt = initial_prompt\n",
    "history = []\n",
    "\n",
    "for i in range(3):  # Run 3 iterations\n",
    "    print(f\"\\nüîÑ Iteration {i+1}\")\n",
    "\n",
    "    # Step 1: Use prompt to extract\n",
    "    results = run_extraction(current_prompt, sample_texts)\n",
    "\n",
    "    # Step 2: Evaluate\n",
    "    metrics = evaluate_results(results, gold_set)\n",
    "    print(f\"üìä F1: {metrics['f1']} | Precision: {metrics['precision']} | Recall: {metrics['recall']}\")\n",
    "\n",
    "    # Save output to file\n",
    "    pd.DataFrame(results).to_csv(f\"iteration2_{i+1}_outputs.csv\", index=False)\n",
    "\n",
    "    # Track history\n",
    "    history.append({\n",
    "        \"iteration\": i + 1,\n",
    "        \"f1\": metrics['f1'],\n",
    "        \"precision\": metrics['precision'],\n",
    "        \"recall\": metrics['recall'],\n",
    "        \"prompt\": current_prompt\n",
    "    })\n",
    "\n",
    "    # Get new prompt\n",
    "    current_prompt = suggest_better_prompt(current_prompt, metrics)\n",
    "    print(f\"üìù New prompt (start):\\n{current_prompt[:500]}...\")\n",
    "\n",
    "# === Save history ===\n",
    "pd.DataFrame(history).to_csv(\"prompt_tuning_history_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f53f6f",
   "metadata": {},
   "source": [
    "### API for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe872944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7531/7531 [2:04:06<00:00,  1.01it/s]  \n"
     ]
    }
   ],
   "source": [
    "# This will hold individual mini-DataFrames returned by analyze_document\n",
    "books_dfs = []\n",
    "\n",
    "for idx, row in tqdm(book_announces.iterrows(), total=len(book_announces), desc=\"Processing articles\"):\n",
    "    article_id = row['article_id']\n",
    "    date = row['date']\n",
    "    raw_text = row['text']\n",
    "    \n",
    "    # Run your analysis\n",
    "    result = analyze_document(raw_text)\n",
    "    \n",
    "    # Handle case where result is a string (either \"NO BOOKS\" or unexpected)\n",
    "    if isinstance(result, str):\n",
    "        if result.strip().upper() == \"NO BOOKS\":\n",
    "            continue\n",
    "        else:\n",
    "            # Optional: parse the string into a DataFrame if the output is line-separated\n",
    "            # But ideally your function should return a proper DataFrame if expected\n",
    "            print(f\"Warning: Expected DataFrame but got string for article_id {article_id}\")\n",
    "            continue\n",
    "    \n",
    "    # Now we're sure result is a DataFrame ‚Äî attach article_id\n",
    "    result['article_id'] = article_id\n",
    "    result['date'] = date\n",
    "    result['text'] = raw_text\n",
    "    books_dfs.append(result)\n",
    "\n",
    "# Concatenate all results\n",
    "books_df = pd.concat(books_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fbf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('../results/all_extracted_titles_250530.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b27b6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10176, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76bc4f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_title\n",
       "NO_BOOK                                                                                              4127\n",
       "De vigtigste indenlandske Tildragelser og de m√¶rkeligste Personers Levnetsbeskrivelser                 24\n",
       "Haandbog for den l√¶sende Ungdom                                                                        22\n",
       "De m√¶rkeligste Personers Levnetsbeskrivelse og de vigtigste Tildragelser igjennem alle Tidsaldere      17\n",
       "Nye Kogebog                                                                                            15\n",
       "Veiledning til Hovedregning eller mental Regnekunst                                                    14\n",
       "Videnskabelig Fortegnelse over Provindsialbogsamlingen i Mariboe                                       14\n",
       "Bibelske Fort√¶llinger med Anvendelse paa Religion og S√¶del√¶re                                          13\n",
       "Thonboes L√¶sebog                                                                                       12\n",
       "Underviisning i Religionen for Ungdommen                                                               12\n",
       "Naturhistorie                                                                                          12\n",
       "Cramers Regnebog                                                                                       11\n",
       "Penelope                                                                                               11\n",
       "Heste og Qv√¶gl√¶ge Tabel                                                                                10\n",
       "Blichers Visdoms og Dyds Tabel                                                                         10\n",
       "Schous Udtog af Forordninger                                                                           10\n",
       "Digte                                                                                                  10\n",
       "De Franskes Keiser Napoleons Levnet                                                                     9\n",
       "Frierens Bes√∏g                                                                                          9\n",
       "Haandbog for l√¶sende Ungdom                                                                             9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df['original_title'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
